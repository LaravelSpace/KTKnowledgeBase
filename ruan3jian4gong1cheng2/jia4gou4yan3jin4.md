## 架构演进

架构设计不是一蹴而就的，是一个不断贴合实际场景并不断演进的过程。

### 基本概念

分布式：系统中的多个模块在不同服务器上部署，即可称为分布式系统。

高可用：系统中部分节点失效时，其他节点能够接替它继续提供服务。

集群：一个特定领域的软件部署在多台服务器上并作为一个整体提供一类服务，这个整体称为集群。在常见的集群中，客户端往往能够连接任意一个节点获得服务，并且当集群中一个节点掉线时，其他节点往往能够自动的接替它继续提供服务，这时候说明集群具有高可用性。

负载均衡：请求发送到系统时，通过某些方式把请求均匀分发到多个节点上，使系统中每个节点能够均匀的处理请求负载，则可认为系统是负载均衡的。

正向代理：系统内部要访问外部网络时，统一通过一个代理服务器把请求转发出去，在外部网络看来就是代理服务器发起的访问，此时代理服务器实现的是正向代理。正向代理是代理服务器代替系统内部来访问外部网络的过程。

反向代理：当外部请求进入系统时，代理服务器把该请求转发到系统中的某台服务器上，对外部请求来说，与之交互的只有代理服务器，此时代理服务器实现的是反向代理。反向代理是外部请求访问系统时通过代理服务器转发到内部服务器的过程。

### 架构演进

文章以淘宝作为例子，介绍从一百个并发到千万级并发情况下服务端的架构的演进过程。

##### 单机架构

一个Web应用在最初时，应用数量和用户数量都比较少，可以把服务端应用和数据库应用都部署在一台服务器上。

##### 第一次演进：Tomcat与数据库分开部署

随着用户数量的增加，服务端应用和数据库应用开始竞争资源，这个时候就需要将两者分开到各自独立的服务器部署。

##### 第二次演进：引入本地缓存和分布式缓存

随着用户数量进一步的增加，数据库并发请求成为瓶颈。但是在这个阶段，数据库读请求的数量和数据库写请求的数量是不成比例的，通常是读请求数量要远大于写请求数量。这个阶段就需要引入缓存，缓存能把大多数的数据库读请求拦截住，从而降低数据库的压力。

这里涉及到本地缓存、分布式缓存、缓存一致性、缓存穿透、缓存雪崩、热点数据集中失效等问题。

##### 第三次演进：引入反向代理实现负载均衡

服务端应用压力进一步上升，一台服务器已经无法满足大量的并发请求，所以就需要在多台服务器上部署服务端应用。这个时候就需要引入反向代理技术，使用反向代理软件把请求均匀的分发到每个服务端应用上。

这里经常涉及到的技术有Nginx和HAProxy，两者都是工作在网络第七层的反向代理软件，主要支持http协议，还会涉及session共享、文件上传下载的问题。假设一个服务端应用能抗住100并发，假设Nginx能抗住50000并发，那么理论上一台服务器部署Nginx再加上50台服务器部署服务端应用就能抗住50000并发。

##### 第四次演进：数据库读写分离

服务端的并发量上去了，以前零星的穿透缓存系统打到数据库上的请求数量就会变得很客观，最终单机数据库会扛不住这样的压力。这时的解决方案就是读写分离。

前面我们说过，通常读请求数量要远大于写请求数量，所以这里读写分离就把原来的单机数据库分离成一个数据库实体处理写请求，另外几个数据库实体处理读请求，通过同步机制将写数据库的数据同步到读数据库。

这里涉及到数据库读写分离，数据库请求分发，数据库数据同步以及数据一致性等问题。

##### 第五次演进：数据库按业务分库

把不同的业务数据保存到不同的数据库中，这样不同的业务就不需要在同一台数据库上互相争抢写请求的资源。但是这样会造成跨业务的表无法做关联分析。

##### 第六次演进：把大表拆分为小表

把大表按某种规律分成小表，可以是时间，可以是id，目的是让数据均匀的出现在每一个小表中。这样服务器应用程序在处理的时候就可以减少操作的数据量。同时可以结合第五次演进的思路把不同的小表分到多个数据库实例上去，实现数据库的水平扩展。

这里涉及到分库分表的管理和请求分发，MPP（大规模并行处理）架构的一类实现。

##### 第七次演进：使用LVS或F5来使多个Nginx负载均衡

通过上面的架构演进，服务端应用和数据库应用都已经可以通过某些手段实现水平扩展了。下一个瓶颈会出现在当前不能扩展的Nginx上。所以就需要想办法让Nginx可以扩展。

这个时候就要用到LVS或F5，这两个是工作在网络第四层的负载均衡解决方案。其中LVS是软件，运行在操作系统内核态，可对TCP请求或更高层级的网络协议进行转发，因此支持的协议更丰富，并且性能也远高于Nginx。F5是一种负载均衡硬件，与LVS提供的能力类似，性能比LVS更高，但价格昂贵。

由于LVS是单机版的软件，若LVS所在服务器宕机则会导致整个后端系统都无法访问，因此需要有备用节点。可使用keepalived软件模拟出虚拟IP，然后把虚拟IP绑定到多台LVS服务器上，浏览器访问虚拟IP时，会被路由器重定向到真实的LVS服务器。当主LVS服务器宕机时，keepalived软件会自动更新路由器中的路由表，把虚拟IP重定向到另外一台正常的LVS服务器，从而达到LVS服务器高可用的效果。

##### 第八次演进：通过DNS轮询实现机房间的负载均衡

上面提到LVS是单机版的软件，所以如果想扩展LVS那就必须想办法在更底层的位置进行请求的分发。这里就要用到的DNS服务器，在DNS服务器中可配置一个域名对应多个IP地址，每个IP地址对应到不同的机房里的虚拟IP。当用户访问应用的外部域名时，DNS服务器会使用轮询策略或其他策略，来选择某个IP供用户访问，此方式能实现机房间的负载均衡。

至此，系统可做到机房级别的水平扩展，千万级到亿级的并发量都可通过增加机房来解决，系统入口处的请求并发量不再是问题。

##### 第九次演进：引入NoSQL数据库和搜索引擎等技术

当数据库中的数据多到一定规模的时候，数据库就不适用于复杂的查询了，往往只能满足普通查询的场景。对于统计报表以及类似场景，在数据量大时不一定能跑出结果，而且在跑复杂查询时由于占用很多的资源会导致其他查询变慢。对于全文检索、可变数据结构等场景，数据库天生不适用。因此需要针对特定的场景，引入合适的解决方案。

如对于海量文件存储，可通过分布式文件系统HDFS解决，对于key-value类型的数据，可通过HBase和Redis等方案解决对于全文检索场景，可通过搜索引擎如ElasticSearch解决，对于多维分析场景，可通过Kylin或Druid等方案解决。引入更多组件同时会提高系统的复杂度，不同的组件保存的数据需要同步，需要考虑一致性的问题，需要有更多的运维手段来管理这些组件。

##### 第十次演进：大应用拆分为小应用

引入更多组件解决了丰富的需求，业务维度能够极大扩充，随之而来的是一个应用中包含了太多的业务代码，业务的升级迭代变得困难。这各阶段就需要按照业务板块来划分应用代码，使单个应用的职责更清晰，相互之间可以做到独立升级迭代。这时候应用之间可能会涉及到一些公共配置，可以通过分布式配置中心Zookeeper来解决。

##### 第十一次演进：复用的功能抽离成微服务

上面的一次演进，已经按照业务模块划分好了各个应用，在各个应用中一定会存在重复的功能模块，那么可以把这些功能的代码单独抽取出来形成一个单独的服务来管理。这样的服务就是所谓的微服务，应用和服务之间通过HTTP、TCP或RPC请求等多种方式来访问公共服务，每个单独的服务都可以由单独的团队来管理。

此外，可以通过Dubbo、SpringCloud等框架实现服务治理、限流、熔断、降级等功能，提高服务的稳定性和可用性。

##### 第十二次演进：引入企业服务总线ESB屏蔽服务接口的访问差异

不同服务的接口访问方式不同，应用代码需要适配多种访问方式才能使用服务，此外，应用访问服务，服务之间也可能相互访问，调用链将会变得非常复杂，逻辑变得混乱。通过ESB统一进行访问协议转换，应用统一通过ESB来访问后端服务，服务与服务之间也通过ESB来相互调用，以此降低系统的耦合程度。

这种单个应用拆分为多个应用，公共服务单独抽取出来来管理，并使用企业消息总线来解除服务之间耦合问题的架构，就是所谓的SOA（面向服务）架构，这种架构与微服务架构容易混淆，因为表现形式十分相似。

##### 第十三次演进：引入容器化技术实现运行环境隔离与动态服务管理

随着业务不断发展，应用和服务都会不断变多，应用和服务的部署变得复杂，同一台服务器上部署多个服务还要解决运行环境冲突的问题此外，对于如大促这类需要动态扩缩容的场景，需要水平扩展服务的性能，就需要在新增的服务上准备运行环境，部署服务等，运维将变得十分困难。

目前最流行的容器化技术是Docker，最流行的容器管理服务是Kubernetes(K8S)，应用/服务可以打包为Docker镜像，通过K8S来动态分发和部署镜像。Docker镜像可理解为一个能运行你的应用/服务的最小的操作系统，里面放着应用/服务的运行代码，运行环境根据实际的需要设置好。把整个操作系统打包为一个镜像后，就可以分发到需要部署相关服务的机器上，直接启动Docker镜像就可以把服务起起来，使服务的部署和运维变得简单。

##### 第十四次演进：以云平台承载系统

使用容器化技术后服务动态扩缩容问题得以解决，但是机器还是需要公司自身来管理，在非大促的时候，还是需要闲置着大量的机器资源来应对大促，机器自身成本和运维成本都极高，资源利用率低。将系统部署到公有云上，利用公有云的海量机器资源，就可以解决动态硬件资源的问题。

所谓的云平台，就是把海量机器资源，通过统一的资源管理，抽象为一个资源整体在云平台上可按需动态申请硬件资源（如CPU、内存、网络等），并且之上提供通用的操作系统，提供常用的技术组件（如Hadoop技术栈，MPP数据库等）供用户使用，甚至提供开发好的应用，用户不需要关心应用内部使用了什么技术就能够解决需求。

在云平台中会涉及如下几个概念：1、IaaS：基础设施即服务。对应于上面所说的机器资源统一为资源整体，可动态申请硬件资源的层面；2、PaaS：平台即服务。对应于上面所说的提供常用的技术组件方便系统的开发和维护；3、SaaS：软件即服务。对应于上面所说的提供开发好的应用或服务，按功能或性能要求付费。

### 总结

以上所提到的从高并发访问问题，到服务的架构和系统实施的层面都有了各自的解决方案。但是架构的演进不是一定要按照上面的路径进行演进的。实际场景中哪个部分先到了瓶颈就先该拿改哪个部分。

对于单次实施并且性能指标明确的系统，架构设计到能够支持系统的性能指标要求就足够了，但要留有扩展架构的接口以便不备之需。对于不断发展的系统，应设计到能满足下一阶段用户量和性能指标要求的程度，并根据业务的增长不断的迭代升级架构，以支持更高的并发和更丰富的业务。

##### 服务端架构和大数据架构有什么区别

所谓的大数据其实是海量数据采集清洗转换、数据存储、数据分析、数据服务等场景解决方案的一个统称，在每一个场景都包含了多种可选的技术。如数据采集有Flume、Sqoop、Kettle等，数据存储有分布式文件系统HDFS、FastDFS，NoSQL数据库HBase、MongoDB等，数据分析有Spark技术栈、机器学习算法等。

总的来说大数据架构就是根据业务的需求，整合各种大数据组件组合而成的架构，一般会提供分布式存储、分布式计算、多维分析、数据仓库、机器学习算法等能力。而服务端架构更多指的是应用组织层面的架构，底层能力往往是由大数据架构来提供。

##### 一些架构设计的原则

N+1设计：系统中的每个组件都应做到没有单点故障；

回滚设计：确保系统可以向前兼容，在系统升级时应能有办法回滚版本；

禁用设计：应该提供控制具体功能是否可用的配置，在系统出现故障时能够快速下线功能；

监控设计：在设计阶段就要考虑监控的手段；

多活数据中心设计：若系统需要极高的高可用，应考虑在多地实施数据中心进行多活，至少在一个机房断电的情况下系统依然可用；

采用成熟的技术：刚开发的或开源的技术往往存在很多隐藏的bug，出了问题没有商业支持可能会是一个灾难；

资源隔离设计：应避免单一业务占用全部资源；

架构应能水平扩展：系统只有做到能水平扩展，才能有效避免瓶颈问题；

非核心则购买：非核心功能若需要占用大量的研发资源才能解决，则考虑购买成熟的产品；

使用商用硬件：商用硬件能有效降低硬件故障的机率；

快速迭代：系统应该快速开发小功能模块，尽快上线进行验证，早日发现问题大大降低系统交付的风险；

无状态设计：服务接口应该做成无状态的，当前接口的访问不依赖于接口上次访问的状态。

---

| 参考来源                                                     |
| ------------------------------------------------------------ |
| [阿里巴巴为什么能抗住90秒100亿？看完这篇你就明白了！](https://www.jianshu.com/p/f4a907fe1485) |