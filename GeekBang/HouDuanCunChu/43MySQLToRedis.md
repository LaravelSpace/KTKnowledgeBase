```json
{
  "updated_by":"KelipuTe",
  "updated_at":"2020-08-05",
  "tags":"极客时间,GeekBang,后端存储实践课"
}
```

---

## MySQL to Redis同步

### 缓存穿透

Redis集群，由于集群可以水平扩容，那只要集群足够大，理论上支持海量并发也不是问题。但是，因为并发请求的数量这个基数太大了，即使有很小比率的请求穿透缓存，打到数据库上请求的绝对数量仍然不小。加上大促期间的流量峰值，还是存在缓存穿透引发雪崩的风险。

解决方案也很简单，反正现在存储也便宜，只要你买得起足够多的服务器，Redis集群的容量就是无限的。不如把全量的数据都放在Redis集群里面，处理读请求的时候，干脆只读Redis，不去读数据库。这样就完全没有缓存穿透的风险了，实际上很多大厂它就是这么干的。

在Redis中缓存全量的数据，又引发了一个新的问题，因为我们取消了缓存穿透的机制，这种情况下，从缓存读到数据可以直接返回，如果没读到数据，那就只能返回错误了。所以，当系统更新数据库的数据之后，必须及时去更新缓存。又绕回到那个老问题上了：怎么保证Redis中的数据和数据库中的数据同步更新？

说到数据库之间的同步肯定会想到分布式事务。但是，分布式事务解决数据一致性的方法都不太适合用来更新缓存，因为分布式事务，对数据更新服务有很强的侵入性。我们拿下单服务来说，如果为了更新缓存增加一个分布式事务，无论我们用哪种分布式事务，或多或少都会影响下单服务的性能。还有一个问题是，如果Redis本身出现故障，写入数据失败，还会导致下单失败，等于是降低了下单服务性能和可用性。

对于像订单服务这类核心的业务，一个可行的方法是，我们启动一个更新订单缓存的服务，接收订单变更的MQ消息，然后更新Redis中缓存的订单数据。因为这类核心的业务数据，使用方非常多，本来就需要发消息，增加一个消费订阅基本没什么成本，订单服务本身也不需要做任何更改。

唯一需要担心的一个问题是：消息丢失。因为现在消息是缓存数据的唯一来源，一旦出现丢消息，缓存里缺失的那条数据永远不会被补上。所以，必须保证整个消息链条的可靠性，不过好在现在的MQ集群，比如像Kafka或者Rocket MQ，它都有高可用和高可靠的保证机制，是可以满足数据可靠性要求的。

### 使用Binlog实时更新Redis缓存

这是一个更通用的解决方案。数据更新服务只负责处理业务逻辑，更新MySQL，完全不用管如何去更新缓存。负责更新缓存的服务，把自己伪装成一个MySQL的从节点，从MySQL接收Binlog，解析Binlog之后，可以得到实时的数据变更信息，然后根据这个变更信息去更新Redis缓存。

这种收Binlog更新缓存的方案，和收MQ消息更新缓存的方案，其实它们的实现思路是一样的，都是异步订阅实时数据变更信息，去更新Redis。只不过，直接读取Binlog这种方式，它的通用性更强。不要求订单服务再发订单消息了，订单更新服务也不用费劲去解决数据一致性问题了。而且，在整个缓存更新链路上，减少了一个收发MQ的环节，从MySQL更新到Redis更新的时延更短，出现故障的可能性也更低。

这个方案唯一的缺点是，实现订单缓存更新服务有点儿复杂，毕竟不像收消息，拿到的直接就是订单数据，解析Binlog还是挺麻烦的。有很多开源的项目就提供了订阅和解析MySQL Binlog的功能，下面我们以比较常用的开源项目**Canal**为例，来演示一下如何实时接收Binlog更新Redis缓存。

Canal模拟MySQL主从复制的交互协议，把自己伪装成一个MySQL的从节点，向MySQL主节点发送dump请求，MySQL收到请求后，就会开始推送Binlog给Canal，Canal解析Binlog字节流之后，转换为便于读取的结构化数据，供下游程序订阅使用。

### 缓存不同步怎么办

设置一个合理的缓存过期时间，这样即使出现缓存不同步，等缓存过期后就会自动恢复。或者识别用户手动刷新操作，强制重新加载缓存数，但要注意防止大量缓存穿透。还可以在管理员的后台系统中，预留一个手动清除缓存的功能，必要的时候人工干预。